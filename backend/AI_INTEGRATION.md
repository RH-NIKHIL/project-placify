# Gemini AI Integration

This project includes a backend-proxied integration with Google Gemini to provide an AI assistant inside the user dashboard.

## Overview
The frontend never calls Gemini directly. Instead it POSTs conversation history to:
```
POST /api/ai/chat
Content-Type: application/json
Authorization: Bearer <JWT>  (optional if you later add auth middleware)
{
  "messages": [
    { "role": "user" | "assistant", "content": "..." },
    ...
  ]
}
```
The server (route: `backend/routes/ai.js`) truncates to the last 12 messages, prepends a system preamble, and calls the Gemini model.

## Setup Steps
1. Install dependency (run inside `backend/` folder):
   ```
   npm install @google/generative-ai
   ```
2. Create a `.env` file in `backend/` (if not already) and add:
   ```
   GEMINI_API_KEY=YOUR_API_KEY_HERE
   # Optional override (default is gemini-1.5-flash)
   GEMINI_MODEL=gemini-1.5-flash
   ```
3. Restart the backend server so the new env vars load.

## Security Notes
- Never expose `GEMINI_API_KEY` to the frontend or commit it to version control.
- Only minimal conversation history (last 12 messages) is sent to control token usage and latency.
- Add rate limiting or auth middleware if you want to restrict who can call the AI route.

## Frontend Usage
The `aiAPI.chat(messages)` function (in `src/services/api.js`) sends the entire current message array. The `UserDashboard` component appends the user message locally then awaits the AI reply.

Example code path:
- UserDashboard `handleSendMessage` builds history and calls `aiAPI.chat`.
- Response is appended to the `messages` state.

## Error Handling
If the key is missing or an upstream error occurs, the route returns:
```
500 { "message": "AI request failed", "error": "<details>" }
```
Frontend converts that into a chat bubble with the error text.

## Future Enhancements
- Streaming responses (use the `streamGenerateContent` API).
- Add per-user conversation persistence in MongoDB.
- Implement moderation / content filtering before returning model output.
- Introduce token usage metrics & logging.

## Troubleshooting
| Issue | Cause | Fix |
|-------|-------|-----|
| 500 GEMINI_API_KEY not configured | Missing env var | Add key to backend/.env and restart |
| AI request failed | Network or quota issue | Check server logs & Google AI quota |
| Slow responses | Large prompts or network latency | Reduce retained messages or switch to lighter model |

---
Last updated: Generated by AI assistant.
